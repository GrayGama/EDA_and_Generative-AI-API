{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec964958",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "from GenAI_backend import (\n",
    "    load_data,\n",
    "    forecast_claims,\n",
    "    summarize_trends,\n",
    "    simulate_policy_change,\n",
    "    forecast_model_selec,  # to train/select models\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94e37658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- OpenAI client ---- \n",
    "# Make sure OPENAI_API_KEY is set in your environment (never hard-code secrets)\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not OPENAI_API_KEY:\n",
    "    raise EnvironmentError(\"OPENAI_API_KEY not found in environment. Set it before running.\")\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# Load modeling data context (provides features/targets to model functions)\n",
    "context = load_data('EDA_output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8727980e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! Here's a joke for you:\n",
      "\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "resp = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello there, tell me a joke, not about atoms.\"}],\n",
    ")\n",
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a84fb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are an analytics assistant for Taiwan's National Health Insurance expenditure data.\n",
    "You have tools to forecast claim costs, summarize trends, and run policy change simulations.\n",
    "\n",
    "Always:\n",
    "- use tools for quantitative questions about forecasts, trends, or scenarios;\n",
    "- explain results in clear, non-technical language;\n",
    "- mention years and magnitudes explicitly (e.g. \"from 2018 to 2023, total claims grew by 15%\").\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d2f9a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"forecast_claims\",\n",
    "            \"description\": \"Forecast next-year claim totals (total/inpatient/outpatient).\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"horizon\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Years ahead to forecast (currently must be 1).\",\n",
    "                        \"default\": 1,\n",
    "                    },\n",
    "                    \"model_name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Name of the model to use: 'xgboost', 'rf', or 'mlp'.\",\n",
    "                        \"enum\": [\"xgboost\", \"rf\", \"mlp\"],\n",
    "                        \"default\": \"xgboost\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"summarize_trends\",\n",
    "            \"description\": \"Compute numeric trend summaries for claims over the last N years.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"window\": {\n",
    "                        \"type\": \"integer\",\n",
    "                        \"description\": \"Number of recent years to summarize (e.g. 3, 5, 10).\",\n",
    "                        \"default\": 5,\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"simulate_policy_change\",\n",
    "            \"description\": (\n",
    "                \"Apply multiplicative shocks to selected features (e.g. insured_persons) \"\n",
    "                \"and estimate impact on forecasted claims.\"\n",
    "            ),\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"shocks\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"description\": (\n",
    "                            \"Mapping from feature name to multiplicative factor. \"\n",
    "                            \"Example: {'insured_persons': 1.10, 'avg_cost_per_person': 0.95}\"\n",
    "                        ),\n",
    "                        \"additionalProperties\": {\"type\": \"number\"},\n",
    "                    },\n",
    "                    \"model_name\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Name of the ML model to use: 'xgboost', 'rf', or 'mlp'.\",\n",
    "                        \"enum\": [\"xgboost\", \"rf\", \"mlp\"],\n",
    "                        \"default\": \"xgboost\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"shocks\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e0d70f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model registry\n",
    "TRAINED_MODELS = {}\n",
    "\n",
    "\n",
    "def init_models():\n",
    "    \"\"\"\n",
    "    Train/select models once and populate TRAINED_MODELS.\n",
    "    Requires a global `context` (loaded via load_data) to be available.\n",
    "    Call this once (in a cell) before chatting.\n",
    "    \"\"\"\n",
    "    for name in [\"xgboost\", \"rf\", \"mlp\"]:\n",
    "        model, metrics = forecast_model_selec(context, name)\n",
    "        TRAINED_MODELS[name] = model\n",
    "        print(f\"Trained model '{name}'; metrics:\\n{metrics}\\n\")\n",
    "\n",
    "\n",
    "def get_trained_model(model_name: str):\n",
    "    if model_name not in TRAINED_MODELS:\n",
    "        raise ValueError(f\"No trained model registered for '{model_name}'.\")\n",
    "    return TRAINED_MODELS[model_name]\n",
    "\n",
    "\n",
    "def call_tool(tool_name: str, arguments: dict) -> str:\n",
    "    \"\"\"\n",
    "    Dispatch a tool call to the underlying Python implementation,\n",
    "    return a JSON string for the LLM.\n",
    "    \"\"\"\n",
    "    if tool_name == \"forecast_claims\":\n",
    "        horizon = arguments.get(\"horizon\", 1)\n",
    "        model_name = arguments.get(\"model_name\", \"xgboost\")\n",
    "        trained_model = get_trained_model(model_name)\n",
    "\n",
    "        result = forecast_claims(\n",
    "            context=context,\n",
    "            horizon=horizon,\n",
    "            model_name=model_name,\n",
    "            trained_model=trained_model,\n",
    "        )\n",
    "\n",
    "    elif tool_name == \"summarize_trends\":\n",
    "        window = arguments.get(\"window\", 5)\n",
    "        summary_dict, _ = summarize_trends(context=context, window=window)\n",
    "        result = {\"window\": window, \"trends\": summary_dict}\n",
    "\n",
    "    elif tool_name == \"simulate_policy_change\":\n",
    "        shocks = arguments[\"shocks\"]\n",
    "        model_name = arguments.get(\"model_name\", \"xgboost\")\n",
    "        trained_model = get_trained_model(model_name)\n",
    "\n",
    "        result = simulate_policy_change(\n",
    "            context=context,\n",
    "            trained_model=trained_model,\n",
    "            model_name=model_name,\n",
    "            shocks=shocks,\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown tool name: {tool_name}\")\n",
    "\n",
    "    return json.dumps(result, default=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce7f1648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_step(\n",
    "    user_input: str,\n",
    "    messages: list,\n",
    "    model: str = \"gpt-4.1-mini\",\n",
    ") -> tuple[str, list]:\n",
    "    \"\"\"\n",
    "    Single chat step for Jupyter:\n",
    "    - takes user's text + current messages history\n",
    "    - lets the model decide whether to call tools\n",
    "    - runs tools if needed\n",
    "    - returns (assistant_reply_text, updated_messages)\n",
    "    \"\"\"\n",
    "\n",
    "    # add user message\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # first call: see if tools are needed\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        tools=tools,\n",
    "        tool_choice=\"auto\",\n",
    "    )\n",
    "\n",
    "    msg = response.choices[0].message\n",
    "\n",
    "    # if there are tool calls, handle them\n",
    "    if msg.tool_calls:\n",
    "        # append the assistant's tool call \"intent\"\n",
    "        messages.append(\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"tool_calls\": msg.tool_calls,\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # run each tool and append its result\n",
    "        for tool_call in msg.tool_calls:\n",
    "            tool_name = tool_call.function.name\n",
    "            args = json.loads(tool_call.function.arguments or \"{}\")\n",
    "\n",
    "            tool_result = call_tool(tool_name, args)\n",
    "\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"tool_call_id\": tool_call.id,\n",
    "                    \"name\": tool_name,\n",
    "                    \"content\": tool_result,\n",
    "                }\n",
    "            )\n",
    "\n",
    "        # second call: model sees tool outputs and answers the user\n",
    "        final_response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "        )\n",
    "        final_msg = final_response.choices[0].message\n",
    "        assistant_text = final_msg.content\n",
    "\n",
    "    else:\n",
    "        # no tools used; direct answer\n",
    "        assistant_text = msg.content\n",
    "\n",
    "    messages.append({\"role\": \"assistant\", \"content\": assistant_text})\n",
    "    return assistant_text, messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89efe3a0",
   "metadata": {},
   "source": [
    "#### Conversation setting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ed960d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claims_total_amt_m         MAE =    5454.92,  RMSE =    6578.55\n",
      "claims_inpatient_amt_m     MAE =    1777.46,  RMSE =    2241.82\n",
      "claims_outpatient_amt_m    MAE =    4105.01,  RMSE =    4966.39\n",
      "Trained model 'xgboost'; metrics:\n",
      "{'claims_total_amt_m': (np.float64(5454.924879807692), np.float64(6578.552332788456)), 'claims_inpatient_amt_m': (np.float64(1777.4624399038462), np.float64(2241.823101870723)), 'claims_outpatient_amt_m': (np.float64(4105.006610576923), np.float64(4966.388714357557))}\n",
      "\n",
      "claims_total_amt_m         MAE =    8591.67,  RMSE =    9719.66\n",
      "claims_inpatient_amt_m     MAE =    1924.78,  RMSE =    2579.71\n",
      "claims_outpatient_amt_m    MAE =    6168.43,  RMSE =    6938.04\n",
      "Trained model 'rf'; metrics:\n",
      "{'claims_total_amt_m': (np.float64(8591.668923076923), np.float64(9719.65623723837)), 'claims_inpatient_amt_m': (np.float64(1924.7818461538448), np.float64(2579.705780205295)), 'claims_outpatient_amt_m': (np.float64(6168.430461538462), np.float64(6938.044455285475))}\n",
      "\n",
      "claims_total_amt_m         MAE =    8591.67,  RMSE =    9719.66\n",
      "claims_inpatient_amt_m     MAE =    1924.78,  RMSE =    2579.71\n",
      "claims_outpatient_amt_m    MAE =    6168.43,  RMSE =    6938.04\n",
      "Trained model 'rf'; metrics:\n",
      "{'claims_total_amt_m': (np.float64(8591.668923076923), np.float64(9719.65623723837)), 'claims_inpatient_amt_m': (np.float64(1924.7818461538448), np.float64(2579.705780205295)), 'claims_outpatient_amt_m': (np.float64(6168.430461538462), np.float64(6938.044455285475))}\n",
      "\n",
      "Starting training...\n",
      "claims_total_amt_m         MAE =    1782.20,  RMSE =    2076.16\n",
      "claims_inpatient_amt_m     MAE =    1195.98,  RMSE =    1778.77\n",
      "claims_outpatient_amt_m    MAE =    1517.98,  RMSE =    1656.13\n",
      "Trained model 'mlp'; metrics:\n",
      "{'claims_total_amt_m': (np.float64(1782.1953125), np.float64(2076.163084212113)), 'claims_inpatient_amt_m': (np.float64(1195.9813701923076), np.float64(1778.7679380406817)), 'claims_outpatient_amt_m': (np.float64(1517.9789663461538), np.float64(1656.1282993388922))}\n",
      "\n",
      "claims_total_amt_m         MAE =    1782.20,  RMSE =    2076.16\n",
      "claims_inpatient_amt_m     MAE =    1195.98,  RMSE =    1778.77\n",
      "claims_outpatient_amt_m    MAE =    1517.98,  RMSE =    1656.13\n",
      "Trained model 'mlp'; metrics:\n",
      "{'claims_total_amt_m': (np.float64(1782.1953125), np.float64(2076.163084212113)), 'claims_inpatient_amt_m': (np.float64(1195.9813701923076), np.float64(1778.7679380406817)), 'claims_outpatient_amt_m': (np.float64(1517.9789663461538), np.float64(1656.1282993388922))}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1) Start a fresh conversation\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "]\n",
    "\n",
    "# 2) Train/load models once\n",
    "init_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3deceb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The forecast for the total National Health Insurance claims in Taiwan for 2024 remains approximately 124.39 billion NTD. This is consistent with the previous forecast and includes around 48.39 billion NTD for inpatient claims and roughly 81.79 billion NTD for outpatient claims. If you would like to explore related insights or detailed breakdowns, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "reply, messages = chat_step(\n",
    "    \"Forecast next year's total claims.\",\n",
    "    messages\n",
    ")\n",
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13bf17d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "預測2024年台灣國民健康保險的醫療費用總額約為1243.86億元新台幣。\n",
      "\n",
      "與2023年實際醫療費用總額約1369.02億元相比，費用將減少約9.17%。也就是說，醫療費用總額在明年預計會比今年降低約9.17%。\n",
      "\n",
      "若需要更多詳細分析或其他年度比較，請告訴我！\n"
     ]
    }
   ],
   "source": [
    "# Example 1: ask for a forecast\n",
    "reply, messages = chat_step(\n",
    "    \"請幫我預測明年的醫療費用總額，並說明和今年相比增加多少百分比？\",\n",
    "    messages,\n",
    ")\n",
    "print(reply)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CathayAPI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
