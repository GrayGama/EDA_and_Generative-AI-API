{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ddd6577",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import statsmodels.api as sm        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ab2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>insured_units</th>\n",
       "      <th>insured_persons</th>\n",
       "      <th>claims_total_cnt_k</th>\n",
       "      <th>claims_total_amt_m</th>\n",
       "      <th>claims_inpatient_cnt_k</th>\n",
       "      <th>claims_outpatient_cnt_k</th>\n",
       "      <th>claims_inpatient_amt_m</th>\n",
       "      <th>claims_outpatient_amt_m</th>\n",
       "      <th>total_cost_per_person</th>\n",
       "      <th>...</th>\n",
       "      <th>claims_inpatient_amt_m_lag1</th>\n",
       "      <th>claims_outpatient_amt_m_lag1</th>\n",
       "      <th>insured_persons_lag1</th>\n",
       "      <th>total_cost_per_person_lag1</th>\n",
       "      <th>inpatient_share_amount_lag1</th>\n",
       "      <th>outpatient_share_amount_lag1</th>\n",
       "      <th>gr_insured_persons</th>\n",
       "      <th>gr_claims_total_amt_m</th>\n",
       "      <th>gr_inpatient_amt_m</th>\n",
       "      <th>gr_outpatient_amt_m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1997</td>\n",
       "      <td>106082</td>\n",
       "      <td>4057159</td>\n",
       "      <td>38602</td>\n",
       "      <td>47885.0</td>\n",
       "      <td>436</td>\n",
       "      <td>19237.0</td>\n",
       "      <td>38166</td>\n",
       "      <td>28648.0</td>\n",
       "      <td>11802.593884</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1998</td>\n",
       "      <td>110119</td>\n",
       "      <td>4072541</td>\n",
       "      <td>38604</td>\n",
       "      <td>48822.0</td>\n",
       "      <td>395</td>\n",
       "      <td>19023.0</td>\n",
       "      <td>38209</td>\n",
       "      <td>29799.0</td>\n",
       "      <td>11988.092938</td>\n",
       "      <td>...</td>\n",
       "      <td>38166.0</td>\n",
       "      <td>28648.0</td>\n",
       "      <td>4057159.0</td>\n",
       "      <td>11802.593884</td>\n",
       "      <td>0.797035</td>\n",
       "      <td>0.598267</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.019568</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>0.040177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999</td>\n",
       "      <td>115306</td>\n",
       "      <td>4108252</td>\n",
       "      <td>37201</td>\n",
       "      <td>40007.0</td>\n",
       "      <td>293</td>\n",
       "      <td>12463.0</td>\n",
       "      <td>36908</td>\n",
       "      <td>27544.0</td>\n",
       "      <td>9738.204959</td>\n",
       "      <td>...</td>\n",
       "      <td>38209.0</td>\n",
       "      <td>29799.0</td>\n",
       "      <td>4072541.0</td>\n",
       "      <td>11988.092938</td>\n",
       "      <td>0.782618</td>\n",
       "      <td>0.610360</td>\n",
       "      <td>0.008769</td>\n",
       "      <td>-0.180554</td>\n",
       "      <td>-0.034050</td>\n",
       "      <td>-0.075674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2000</td>\n",
       "      <td>124806</td>\n",
       "      <td>4195952</td>\n",
       "      <td>41775</td>\n",
       "      <td>55529.0</td>\n",
       "      <td>469</td>\n",
       "      <td>21618.0</td>\n",
       "      <td>41307</td>\n",
       "      <td>33911.0</td>\n",
       "      <td>13233.945479</td>\n",
       "      <td>...</td>\n",
       "      <td>36908.0</td>\n",
       "      <td>27544.0</td>\n",
       "      <td>4108252.0</td>\n",
       "      <td>9738.204959</td>\n",
       "      <td>0.922539</td>\n",
       "      <td>0.688480</td>\n",
       "      <td>0.021347</td>\n",
       "      <td>0.387982</td>\n",
       "      <td>0.119188</td>\n",
       "      <td>0.231157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2001</td>\n",
       "      <td>125022</td>\n",
       "      <td>4263321</td>\n",
       "      <td>39948</td>\n",
       "      <td>51875.0</td>\n",
       "      <td>435</td>\n",
       "      <td>20172.0</td>\n",
       "      <td>39512</td>\n",
       "      <td>31703.0</td>\n",
       "      <td>12167.744348</td>\n",
       "      <td>...</td>\n",
       "      <td>41307.0</td>\n",
       "      <td>33911.0</td>\n",
       "      <td>4195952.0</td>\n",
       "      <td>13233.945479</td>\n",
       "      <td>0.743882</td>\n",
       "      <td>0.610690</td>\n",
       "      <td>0.016056</td>\n",
       "      <td>-0.065803</td>\n",
       "      <td>-0.043455</td>\n",
       "      <td>-0.065112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  insured_units  insured_persons  claims_total_cnt_k  \\\n",
       "0  1997         106082          4057159               38602   \n",
       "1  1998         110119          4072541               38604   \n",
       "2  1999         115306          4108252               37201   \n",
       "3  2000         124806          4195952               41775   \n",
       "4  2001         125022          4263321               39948   \n",
       "\n",
       "   claims_total_amt_m  claims_inpatient_cnt_k  claims_outpatient_cnt_k  \\\n",
       "0             47885.0                     436                  19237.0   \n",
       "1             48822.0                     395                  19023.0   \n",
       "2             40007.0                     293                  12463.0   \n",
       "3             55529.0                     469                  21618.0   \n",
       "4             51875.0                     435                  20172.0   \n",
       "\n",
       "   claims_inpatient_amt_m  claims_outpatient_amt_m  total_cost_per_person  \\\n",
       "0                   38166                  28648.0           11802.593884   \n",
       "1                   38209                  29799.0           11988.092938   \n",
       "2                   36908                  27544.0            9738.204959   \n",
       "3                   41307                  33911.0           13233.945479   \n",
       "4                   39512                  31703.0           12167.744348   \n",
       "\n",
       "   ...  claims_inpatient_amt_m_lag1  claims_outpatient_amt_m_lag1  \\\n",
       "0  ...                          NaN                           NaN   \n",
       "1  ...                      38166.0                       28648.0   \n",
       "2  ...                      38209.0                       29799.0   \n",
       "3  ...                      36908.0                       27544.0   \n",
       "4  ...                      41307.0                       33911.0   \n",
       "\n",
       "   insured_persons_lag1  total_cost_per_person_lag1  \\\n",
       "0                   NaN                         NaN   \n",
       "1             4057159.0                11802.593884   \n",
       "2             4072541.0                11988.092938   \n",
       "3             4108252.0                 9738.204959   \n",
       "4             4195952.0                13233.945479   \n",
       "\n",
       "   inpatient_share_amount_lag1  outpatient_share_amount_lag1  \\\n",
       "0                          NaN                           NaN   \n",
       "1                     0.797035                      0.598267   \n",
       "2                     0.782618                      0.610360   \n",
       "3                     0.922539                      0.688480   \n",
       "4                     0.743882                      0.610690   \n",
       "\n",
       "   gr_insured_persons  gr_claims_total_amt_m  gr_inpatient_amt_m  \\\n",
       "0                 NaN                    NaN                 NaN   \n",
       "1            0.003791               0.019568            0.001127   \n",
       "2            0.008769              -0.180554           -0.034050   \n",
       "3            0.021347               0.387982            0.119188   \n",
       "4            0.016056              -0.065803           -0.043455   \n",
       "\n",
       "   gr_outpatient_amt_m  \n",
       "0                  NaN  \n",
       "1             0.040177  \n",
       "2            -0.075674  \n",
       "3             0.231157  \n",
       "4            -0.065112  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"EDA_output.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49690e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_cols = [\n",
    "    # base level\n",
    "    \"insured_persons\",\n",
    "    \"inpatient_share_amount\",\n",
    "    \"outpatient_share_amount\",\n",
    "    # Avg cost per claim\n",
    "    \"total_cost_per_person\",\n",
    "    \"impatient_cost_per_person\",\n",
    "    \"outpatient_cost_per_person\",\n",
    "    \"avg_cost_per_claim\",\n",
    "    \"avg_impatient_cost_per_claim\",\n",
    "    \"avg_outpatient_cost_per_claim\",\n",
    "    # lags\n",
    "    \"claims_total_amt_m_lag1\",\n",
    "    \"insured_persons_lag1\",\n",
    "    # growths\n",
    "    \"gr_claims_total_amt_m\",\n",
    "    \"gr_insured_persons\"\n",
    "]\n",
    "\n",
    "target_cols = [\"claims_total_amt_m\", \"claims_inpatient_amt_m\", \"claims_outpatient_amt_m\"]\n",
    "\n",
    "supervised = df[[\"year\"] + feature_cols + target_cols].dropna().reset_index(drop=True)\n",
    "X = supervised[feature_cols].values\n",
    "y = supervised[target_cols].values\n",
    "years = supervised[\"year\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6874b176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input features: 13\n",
      "Output features: 3\n"
     ]
    }
   ],
   "source": [
    "### ----- For Pytorch -------------\n",
    "### Agnostic code\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device\n",
    "\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "in_dim = X.shape[1]\n",
    "out_dim = y.shape[1]\n",
    "\n",
    "lr=1e-2\n",
    "weigh_decay=1e-2\n",
    "\n",
    "print(f\"Input features: {in_dim}\")\n",
    "print(f\"Output features: {out_dim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8d81f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_MAE_RMSE(target_cols, y_true, y_pred):\n",
    "    results = {}\n",
    "    for j, name in enumerate(target_cols):\n",
    "        mae = mean_absolute_error(y_true[:, j], y_pred[:, j])\n",
    "        rmse = np.sqrt(mean_squared_error(y_true[:, j], y_pred[:, j]))  \n",
    "        print(f\"{name:25s}  MAE = {mae:10.2f},  RMSE = {rmse:10.2f}\")\n",
    "        results[name] = (mae, rmse)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3c7dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_origin_eval_multi(X, y, years, model, min_train_size=8):\n",
    "    \"\"\"\"\n",
    "    X: (N, d)\n",
    "    y: (N, T) multi-output targets\n",
    "    years: (N,)\n",
    "    model: regressor supporting multi-output (or wrapped model)\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    actuals = []\n",
    "    pred_years = []\n",
    "    \n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    for split in range(min_train_size, n_samples):\n",
    "        X_train, y_train = X[:split], y[:split]\n",
    "        X_test, y_test = X[split].reshape(1, -1), y[split]\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)[0]\n",
    "        \n",
    "        preds.append(y_pred)\n",
    "        actuals.append(y_test)\n",
    "        pred_years.append(years[split])\n",
    "    \n",
    "    return model, np.array(preds), np.array(actuals), np.array(pred_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a0cf2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPRegressor(nn.Module):\n",
    "    def __init__(self, input_dim=in_dim, output_dim=out_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, output_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "634c9218",
   "metadata": {},
   "outputs": [],
   "source": [
    "### ---- For Pytorch training loop  ------- \n",
    "\n",
    "def train_torch_mlp(X_train, y_train, n_epochs=200, lr=1e-2, weigh_decay=1e-2, batch_size=None):\n",
    "    \"\"\"\n",
    "    Train an MLPRegressor on X_train, y_train (numpy arrays).\n",
    "    Returns: trained model, scaler_X, scaler_y\n",
    "    \"\"\"\n",
    "    import torchmetrics\n",
    "    \n",
    "    scaler_X = StandardScaler()\n",
    "    scaler_y = StandardScaler()\n",
    "    \n",
    "    X_train_scaled = scaler_X.fit_transform(X_train)\n",
    "    y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "    \n",
    "    X_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "    y_tensor = torch.tensor(y_train_scaled, dtype=torch.float32).to(device)\n",
    "    \n",
    "    if batch_size is None or batch_size > X_tensor.shape[0]:\n",
    "        batch_size = X_tensor.shape[0]\n",
    "        \n",
    "    dataset = TensorDataset(X_tensor, y_tensor)\n",
    "    loader = DataLoader(dataset, \n",
    "                        batch_size=batch_size,\n",
    "                        shuffle=True)\n",
    "    \n",
    "    mlp_model = MLPRegressor(input_dim=X_train.shape[1], output_dim=y_train.shape[1]).to(device)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    optimizer = torch.optim.Adam(mlp_model.parameters(),\n",
    "                            lr=lr,\n",
    "                            weight_decay=weigh_decay)\n",
    "    # Initialize torchmetrics\n",
    "    mae_metric = torchmetrics.MeanAbsoluteError().to(device)\n",
    "    mse_metric = torchmetrics.MeanSquaredError().to(device)\n",
    "    \n",
    "    mlp_model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        mae_metric.reset()\n",
    "        mse_metric.reset()\n",
    "        \n",
    "        for xb, yb in loader:\n",
    "            optimizer.zero_grad()\n",
    "            pred = mlp_model(xb)\n",
    "            loss = criterion(pred, yb)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * xb.size(0)\n",
    "            \n",
    "            # Update metrics\n",
    "            mae_metric.update(pred, yb)\n",
    "            mse_metric.update(pred, yb)\n",
    "        \n",
    "        # Calculate average loss for the epoch\n",
    "        epoch_loss /= X_tensor.shape[0]\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            mae = mae_metric.compute()\n",
    "            rmse = torch.sqrt(mse_metric.compute())\n",
    "            print(f\"Epoch {epoch:3d}/{n_epochs} - Loss: {epoch_loss:.6f} | MAE: {mae:.6f} | RMSE: {rmse:.6f}\")\n",
    "    \n",
    "    return mlp_model, scaler_X, scaler_y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fba6e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPWrapper:\n",
    "    def __init__(self, model, scaler_X, scaler_y):\n",
    "        self.model = model\n",
    "        self.scaler_X = scaler_X\n",
    "        self.scaler_y = scaler_y\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_scaled = self.scaler_X.transform(X)\n",
    "        X_tensor = torch.tensor(X_scaled, dtype=torch.float32).to(device)\n",
    "        self.model.eval()\n",
    "        with torch.inference_mode():\n",
    "            y_scaled = self.model(X_tensor).cpu().numpy()\n",
    "        return self.scaler_y.inverse_transform(y_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46b1e641",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_origin_eval_torch(X, y, years, min_train_size=8, n_epochs=200, lr=1e-2, weight_decay=1e-2, batch_size=None):\n",
    "    \"\"\"\"\n",
    "    X: (N, d)\n",
    "    y: (N, T) multi-output targets\n",
    "    years: (N,)\n",
    "    model: regressor supporting multi-output (or wrapped model)\n",
    "    \"\"\"\n",
    "    preds = []\n",
    "    actuals = []\n",
    "    pred_years = []\n",
    "    \n",
    "    n_samples = X.shape[0]\n",
    "    \n",
    "    for split in range(min_train_size, n_samples):\n",
    "        X_train, y_train = X[:split], y[:split]\n",
    "        \n",
    "        mlp_model, scaler_X, scaler_y = train_torch_mlp(X_train, y_train, \n",
    "                                                        n_epochs=n_epochs, \n",
    "                                                        lr=lr, \n",
    "                                                        weight_decay=weight_decay, \n",
    "                                                        batch_size=batch_size)\n",
    "        \n",
    "        X_test = X[split].reshape(1, -1)\n",
    "        X_test_scaled = scaler_X.transform(X_test)\n",
    "        X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "        y_test = y[split]\n",
    "        \n",
    "        mlp_model.eval()\n",
    "        with torch.inference_mode():\n",
    "            y_pred_scaled = mlp_model(X_test_tensor).cpu().numpy()\n",
    "        \n",
    "        y_pred = scaler_y.inverse_transform(y_pred_scaled)[0]\n",
    "    \n",
    "        preds.append(y_pred)\n",
    "        actuals.append(y_test)\n",
    "        pred_years.append(years[split])\n",
    "        \n",
    "        # keep last model + scalers\n",
    "        final_model = mlp_model\n",
    "        final_scaler_X = scaler_X\n",
    "        final_scaler_y = scaler_y\n",
    "        \n",
    "        mlp_wrapper = MLPWrapper(final_model, final_scaler_X, final_scaler_y)\n",
    "    \n",
    "    return mlp_wrapper, np.array(preds), np.array(actuals), np.array(pred_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85b667a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_origin_arima(y_series, years, order=(1,1,1), min_train_size=8):\n",
    "    preds, actuals, pred_years = [], [], []\n",
    "    n = len(y_series)\n",
    "\n",
    "    for split in range(min_train_size, n):\n",
    "\n",
    "        # Train ARIMA on y[:split]\n",
    "        model = sm.tsa.ARIMA(y_series[:split], order=order)\n",
    "        result = model.fit()\n",
    "\n",
    "        # Predict next year (t+1)\n",
    "        pred = result.forecast(steps=1)[0]\n",
    "        true = y_series[split]\n",
    "\n",
    "        preds.append(pred)\n",
    "        actuals.append(true)\n",
    "        pred_years.append(years[split])\n",
    "\n",
    "    return np.array(preds), np.array(actuals), np.array(pred_years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7a688903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mae_rmse_single(name, y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    print(f\"{name:25s}  MAE = {mae:10.2f},  RMSE = {rmse:10.2f}\")\n",
    "    return mae, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea52e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_model_selec(model_name=\"xgboost\"):\n",
    "    \"\"\"\n",
    "    Select the model and run rolling-origin evaluation, print MAE/RMSE for selected targets.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trained_model : fitted model or None\n",
    "        - 'rf' / 'xgboost' : fitted multi-output model\n",
    "        - 'mlp'           : fitted torch model (as returned by rolling_origin_eval_torch)\n",
    "        - 'arima'         : None for now (ARIMA serving not wired yet)\n",
    "    results : dict or DataFrame\n",
    "        MAE/RMSE per target.\n",
    "    \"\"\"\n",
    "    if model_name == \"rf\":\n",
    "        rf_base = RandomForestRegressor(\n",
    "            n_estimators=500,\n",
    "            max_depth=None,\n",
    "            min_samples_split=2,\n",
    "            min_samples_leaf=1,\n",
    "            # max_features='auto',\n",
    "            random_state=42, \n",
    "        )\n",
    "        trained_model, preds, actuals, pred_years = rolling_origin_eval_multi(X, y, years, rf_base, min_train_size=8)\n",
    "    elif model_name == \"xgboost\":\n",
    "        xgb_base = XGBRegressor(\n",
    "            objective=\"reg:squarederror\",\n",
    "            n_estimators=300,\n",
    "            max_depth=3,\n",
    "            learning_rate=0.05,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            reg_lambda=1.0,\n",
    "            random_state=42,\n",
    "        )\n",
    "        base_model = MultiOutputRegressor(xgb_base)  # MultiOutputRegressor(XGBRegressor) \n",
    "        trained_model, preds, actuals, pred_years = rolling_origin_eval_multi(X, y, years, base_model, min_train_size=8)\n",
    "    elif model_name == \"mlp\":\n",
    "        # You may prefer to re-train or store a fitted MLP\n",
    "        trained_model, preds, actuals, pred_years = rolling_origin_eval_torch(X, y, years)\n",
    "    elif model_name == \"arima\":\n",
    "        # ARIMA-only forecast for total, inpatient, outpatient\n",
    "        preds, actuals, years = rolling_origin_arima(\n",
    "            y[:, 0], years, order=(1,1,1)\n",
    "        )\n",
    "        mae, rmse = calculate_mae_rmse_single(\"claims_total_amt_m\", actuals, preds)\n",
    "        results_a = {\"claims_total_amt_m\": (mae, rmse)}\n",
    "        return None, results_a\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model_name: {model_name}\")\n",
    "    \n",
    "    results = Calculate_MAE_RMSE(target_cols, actuals, preds) \n",
    "    \n",
    "    return trained_model, results\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39ecf632",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forecast_claims(horizon=1, model_name=None, trained_model=None):\n",
    "    \"\"\"\n",
    "    Use a trained model to forecast claims_total_amt_m, claims_inpatient_amt_m,\n",
    "    claims_outpatient_amt_m for the next `horizon` years from the last available year.\n",
    "\n",
    "    For now: horizon=1 only.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    horizon : int\n",
    "        Number of years ahead to forecast (currently must be 1).\n",
    "    model_name : str or None\n",
    "        Optional explicit model name: 'xgboost', 'rf', 'mlp', 'arima'.\n",
    "        If None, it will be inferred from `trained_model`.\n",
    "    trained_model :\n",
    "        - 'xgboost'/'rf'/'multioutput': fitted sklearn regressor with .predict(X)\n",
    "        - 'mlp'                     : MLPWrapper instance exposing .predict(X)\n",
    "        - 'arima'                   : dict {target_name: fitted ARIMA result object}\n",
    "    \"\"\"\n",
    "\n",
    "    # --- small helper: infer model_name from the trained_model type ---\n",
    "    def _infer_model_name(m):\n",
    "        # ARIMA: dict of results objects\n",
    "        if isinstance(m, dict):\n",
    "            return \"arima\"\n",
    "\n",
    "        # Try to detect sklearn / xgboost types\n",
    "        try:\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "            from sklearn.multioutput import MultiOutputRegressor\n",
    "        except ImportError:\n",
    "            RandomForestRegressor = type(\"RFPlaceholder\", (), {})\n",
    "            MultiOutputRegressor = type(\"MOPPlaceholder\", (), {})\n",
    "\n",
    "        try:\n",
    "            from xgboost import XGBRegressor\n",
    "        except ImportError:\n",
    "            XGBRegressor = type(\"XGBPlaceholder\", (), {})\n",
    "\n",
    "        # RF\n",
    "        if isinstance(m, RandomForestRegressor):\n",
    "            return \"rf\"\n",
    "\n",
    "        # MultiOutputRegressor(XGBRegressor)\n",
    "        if isinstance(m, MultiOutputRegressor):\n",
    "            if isinstance(m.estimator, XGBRegressor):\n",
    "                return \"xgboost\"\n",
    "            # generic multi-output – you can extend this if you add more models\n",
    "            return \"multioutput\"\n",
    "\n",
    "        # (Optional) detect MLP by torch.nn.Module\n",
    "        try:\n",
    "            import torch.nn as nn\n",
    "            if isinstance(m, nn.Module):\n",
    "                return \"mlp\"\n",
    "        except ImportError:\n",
    "            pass\n",
    "\n",
    "        return None\n",
    "\n",
    "    # ----------------- basic checks -----------------\n",
    "    last_row = supervised.iloc[-1]\n",
    "    last_year = int(last_row[\"year\"])\n",
    "\n",
    "    if horizon != 1:\n",
    "        raise NotImplementedError(\"forecast_claims currently supports horizon=1 only.\")\n",
    "\n",
    "    if trained_model is None:\n",
    "        raise ValueError(\n",
    "            \"forecast_claims expected a pre-trained model. \"\n",
    "            \"Call forecast_model_selec() first and pass its trained_model here.\"\n",
    "        )\n",
    "\n",
    "    # auto-infer model_name if not provided\n",
    "    if model_name is None:\n",
    "        model_name = _infer_model_name(trained_model)\n",
    "        if model_name is None:\n",
    "            raise ValueError(\n",
    "                \"Could not infer model_name from trained_model. \"\n",
    "                \"Please pass model_name explicitly (e.g. 'xgboost', 'rf', 'arima').\"\n",
    "            )\n",
    "\n",
    "    # ---------- ARIMA branch ----------\n",
    "    if model_name == \"arima\":\n",
    "        # trained_model is expected to be dict: {col_name: ARIMAResults-like}\n",
    "        forecasts = {}\n",
    "        for col in target_cols:\n",
    "            arima_result = trained_model[col]   # ARIMAResults\n",
    "            pred = float(arima_result.forecast(steps=1)[-1])\n",
    "            forecasts[col] = pred\n",
    "\n",
    "        return {\n",
    "            \"base_year\": last_year,\n",
    "            \"forecast_year\": last_year + 1,\n",
    "            \"model_name\": \"arima\",\n",
    "            \"forecasts\": forecasts,\n",
    "        }\n",
    "\n",
    "    # ---------- ML multi-output branch ----------\n",
    "    X_last = last_row[feature_cols].values.reshape(1, -1)\n",
    "\n",
    "    if model_name in [\"xgboost\", \"rf\", \"multioutput\", \"mlp\"]:\n",
    "        # MultiOutputRegressor(XGBRegressor) or RandomForestRegressor\n",
    "        y_pred = trained_model.predict(X_last)[0]  # shape: (n_targets,)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown or unsupported model_name: {model_name}\")\n",
    "\n",
    "    forecasts = {name: float(val) for name, val in zip(target_cols, y_pred)}\n",
    "\n",
    "    return {\n",
    "        \"base_year\": last_year,\n",
    "        \"forecast_year\": last_year + 1,\n",
    "        \"model_name\": model_name,\n",
    "        \"forecasts\": forecasts,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6657f4",
   "metadata": {},
   "source": [
    "### Numeric trend summary\n",
    "\n",
    "This gives the LLM everything it needs to say things like:\n",
    "\n",
    "“Over the last 5 years, total claims increased by 23% (CAGR ~4.2%/year), with volatility (std) of …”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eda2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_trends(window=5):\n",
    "    \"\"\"\n",
    "    Compute numeric trend summaries over the last `window` years for each target.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    summary_dict : dict\n",
    "        {\n",
    "          target_name: {\n",
    "            'start_year': int,\n",
    "            'end_year': int,\n",
    "            'start_value': float,\n",
    "            'end_value': float,\n",
    "            'abs_change': float,\n",
    "            'pct_change': float,   # in %\n",
    "            'cagr': float,         # in % per year\n",
    "            'mean': float,\n",
    "            'std': float,\n",
    "          },\n",
    "          ...\n",
    "        }\n",
    "    summary_df : pd.DataFrame\n",
    "        Tabular version of the same information.\n",
    "    \"\"\"\n",
    "    # Aggregate to yearly sums (or use .mean() if that makes more sense for you)\n",
    "    yearly = (\n",
    "        supervised\n",
    "        .groupby(\"year\")[target_cols]\n",
    "        .sum()\n",
    "        .sort_index()\n",
    "    )\n",
    "\n",
    "    if yearly.shape[0] < 2:\n",
    "        raise ValueError(\"Not enough years of data to summarize trends.\")\n",
    "\n",
    "    # restrict to last `window` years if available\n",
    "    if yearly.shape[0] > window:\n",
    "        yearly_window = yearly.iloc[-window:]\n",
    "    else:\n",
    "        yearly_window = yearly\n",
    "\n",
    "    years_idx = yearly_window.index.to_numpy()\n",
    "    start_year = int(years_idx[0])\n",
    "    end_year = int(years_idx[-1])\n",
    "    n_periods = len(years_idx) - 1  # for CAGR\n",
    "\n",
    "    summary_rows = []\n",
    "\n",
    "    for col in target_cols:\n",
    "        series = yearly_window[col].astype(float)\n",
    "        start_val = float(series.iloc[0])\n",
    "        end_val = float(series.iloc[-1])\n",
    "        abs_change = end_val - start_val\n",
    "\n",
    "        if start_val != 0:\n",
    "            pct_change = (abs_change / start_val) * 100.0\n",
    "        else:\n",
    "            pct_change = float(\"nan\")\n",
    "\n",
    "        # CAGR: (end/start)^(1/years) - 1\n",
    "        if start_val > 0 and n_periods > 0:\n",
    "            cagr = ((end_val / start_val) ** (1.0 / n_periods) - 1.0) * 100.0\n",
    "        else:\n",
    "            cagr = float(\"nan\")\n",
    "\n",
    "        mean_val = float(series.mean())\n",
    "        std_val = float(series.std(ddof=1)) if len(series) > 1 else float(\"nan\")\n",
    "\n",
    "        row = {\n",
    "            \"target\": col,\n",
    "            \"start_year\": start_year,\n",
    "            \"end_year\": end_year,\n",
    "            \"start_value\": start_val,\n",
    "            \"end_value\": end_val,\n",
    "            \"abs_change\": abs_change,\n",
    "            \"pct_change\": pct_change,\n",
    "            \"cagr\": cagr,\n",
    "            \"mean\": mean_val,\n",
    "            \"std\": std_val,\n",
    "        }\n",
    "        summary_rows.append(row)\n",
    "\n",
    "    summary_df = pd.DataFrame(summary_rows).set_index(\"target\")\n",
    "    summary_dict = {row[\"target\"]: {k: v for k, v in row.items() if k != \"target\"}\n",
    "                    for row in summary_rows}\n",
    "\n",
    "    return summary_dict, summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ff22aa",
   "metadata": {},
   "source": [
    "### Feature shocks + Impact\n",
    "\n",
    "Goal: “If I change some drivers (insured people, cost per person, etc.) by X%, what happens to next year’s claims?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d937c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_policy_change(trained_model, model_name=None, shocks=None, horizon=1):\n",
    "    \"\"\"\n",
    "    Apply multiplicative shocks to selected features and compute impact on forecasted claims.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    trained_model :\n",
    "        Fitted model with .predict(X) interface (RF/XGB/MultiOutputRegressor/MLPWrapper).\n",
    "    model_name : str or None\n",
    "        'xgboost', 'rf', 'mlp', 'multioutput', 'arima', or None to infer.\n",
    "    shocks : dict or None\n",
    "        Mapping feature_name -> multiplicative factor.\n",
    "        Example: {'insured_persons': 1.10, 'avg_cost_per_person': 0.95}\n",
    "        If None or empty dict, no changes applied.\n",
    "    horizon : int\n",
    "        Currently must be 1 (same limitation as forecast_claims).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : dict\n",
    "        {\n",
    "          'base_year': int,\n",
    "          'forecast_year': int,\n",
    "          'model_name': str,\n",
    "          'baseline_forecasts': {target: float},\n",
    "          'scenario_forecasts': {target: float},\n",
    "          'impact': {\n",
    "             target: {\n",
    "                'abs_change': float,\n",
    "                'pct_change': float\n",
    "             },\n",
    "             ...\n",
    "          },\n",
    "          'applied_shocks': shocks_dict actually used,\n",
    "        }\n",
    "    \"\"\"\n",
    "\n",
    "    if shocks is None:\n",
    "        shocks = {}\n",
    "\n",
    "    # --- helper: reuse the same infer logic used in forecast_claims ---\n",
    "    def _infer_model_name(m):\n",
    "        if isinstance(m, dict):\n",
    "            return \"arima\"\n",
    "\n",
    "        try:\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "            from sklearn.multioutput import MultiOutputRegressor\n",
    "        except ImportError:\n",
    "            RandomForestRegressor = type(\"RFPlaceholder\", (), {})\n",
    "            MultiOutputRegressor = type(\"MOPPlaceholder\", (), {})\n",
    "\n",
    "        try:\n",
    "            from xgboost import XGBRegressor\n",
    "        except ImportError:\n",
    "            XGBRegressor = type(\"XGBPlaceholder\", (), {})\n",
    "\n",
    "        if isinstance(m, RandomForestRegressor):\n",
    "            return \"rf\"\n",
    "\n",
    "        if isinstance(m, MultiOutputRegressor):\n",
    "            if isinstance(m.estimator, XGBRegressor):\n",
    "                return \"xgboost\"\n",
    "            return \"multioutput\"\n",
    "\n",
    "        # MLPWrapper\n",
    "        try:\n",
    "            if isinstance(m, MLPWrapper):\n",
    "                return \"mlp\"\n",
    "        except NameError:\n",
    "            pass\n",
    "\n",
    "        try:\n",
    "            import torch.nn as nn\n",
    "            if isinstance(m, nn.Module):\n",
    "                return \"mlp\"\n",
    "        except ImportError:\n",
    "            pass\n",
    "\n",
    "        return None\n",
    "\n",
    "    if trained_model is None:\n",
    "        raise ValueError(\"simulate_policy_change requires a trained_model.\")\n",
    "\n",
    "    if horizon != 1:\n",
    "        raise NotImplementedError(\"simulate_policy_change currently supports horizon=1 only.\")\n",
    "\n",
    "    # infer model_name if needed\n",
    "    if model_name is None:\n",
    "        model_name = _infer_model_name(trained_model)\n",
    "        if model_name is None:\n",
    "            raise ValueError(\n",
    "                \"Could not infer model_name from trained_model. \"\n",
    "                \"Please pass model_name explicitly (e.g. 'xgboost', 'rf', 'mlp').\"\n",
    "            )\n",
    "\n",
    "    if model_name == \"arima\":\n",
    "        raise NotImplementedError(\n",
    "            \"simulate_policy_change is not implemented for ARIMA-only models, \"\n",
    "            \"since it relies on feature shocks.\"\n",
    "        )\n",
    "\n",
    "    # ---------- baseline forecast using existing tool ----------\n",
    "    baseline = forecast_claims(\n",
    "        horizon=horizon,\n",
    "        model_name=model_name,\n",
    "        trained_model=trained_model,\n",
    "    )\n",
    "    baseline_forecasts = baseline[\"forecasts\"]\n",
    "    base_year = baseline[\"base_year\"]\n",
    "    forecast_year = baseline[\"forecast_year\"]\n",
    "\n",
    "    # ---------- build scenario features ----------\n",
    "    last_row = supervised.iloc[-1].copy()\n",
    "\n",
    "    applied_shocks = {}\n",
    "\n",
    "    for feat, factor in shocks.items():\n",
    "        if feat in last_row.index:\n",
    "            original_val = last_row[feat]\n",
    "            last_row[feat] = original_val * factor\n",
    "            applied_shocks[feat] = {\n",
    "                \"original\": float(original_val),\n",
    "                \"factor\": float(factor),\n",
    "                \"new_value\": float(last_row[feat]),\n",
    "            }\n",
    "        else:\n",
    "            # feature name not found; you could also warn/log instead of ignoring.\n",
    "            # For now just skip it.\n",
    "            continue\n",
    "\n",
    "    X_scenario = last_row[feature_cols].values.reshape(1, -1)\n",
    "\n",
    "    # ---------- scenario prediction ----------\n",
    "    # trained_model implements .predict for all supported model_name values\n",
    "    y_pred_scenario = trained_model.predict(X_scenario)[0]  # (n_targets,)\n",
    "\n",
    "    scenario_forecasts = {\n",
    "        name: float(val) for name, val in zip(target_cols, y_pred_scenario)\n",
    "    }\n",
    "\n",
    "    # ---------- impact calculation ----------\n",
    "    impact = {}\n",
    "    for tgt in target_cols:\n",
    "        base_val = float(baseline_forecasts[tgt])\n",
    "        scen_val = float(scenario_forecasts[tgt])\n",
    "        abs_change = scen_val - base_val\n",
    "        if base_val != 0:\n",
    "            pct_change = (abs_change / base_val) * 100.0\n",
    "        else:\n",
    "            pct_change = float(\"nan\")\n",
    "        impact[tgt] = {\n",
    "            \"abs_change\": abs_change,\n",
    "            \"pct_change\": pct_change,\n",
    "        }\n",
    "\n",
    "    result = {\n",
    "        \"base_year\": base_year,\n",
    "        \"forecast_year\": forecast_year,\n",
    "        \"model_name\": model_name,\n",
    "        \"baseline_forecasts\": baseline_forecasts,\n",
    "        \"scenario_forecasts\": scenario_forecasts,\n",
    "        \"impact\": impact,\n",
    "        \"applied_shocks\": applied_shocks,\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CathayAPI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
